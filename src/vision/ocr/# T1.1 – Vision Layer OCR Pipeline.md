# T1.1 – Vision Layer: OCR Pipeline (Production Ready)

## Overview

This document describes the complete implementation of **T1.1 – OCR Pipeline** for Phase 1 (Vision Layer).  
The objective of T1.1 was to build a **robust, configurable, and extensible OCR pipeline** using **Docling** as the primary engine, with **Tesseract** and **TrOCR** added for comparison.

The task focused strictly on:
- OCR engine wrappers
- CLI tooling
- Error handling and robustness
- Engine isolation and comparison readiness

**Accuracy validation and benchmarking are explicitly deferred to T1.4.**

---

## Final Status

**Status:** ✅ COMPLETE  
**Phase:** Phase 1 – Vision Layer  
**Task:** T1.1 OCR Pipeline  

---

## Folder Structure

src/
└── vision/
└── ocr/
├── run_ocr.py # Main CLI entrypoint
├── engines/
│ ├── base.py # Shared engine interface
│ ├── docling_engine.py # Primary OCR engine (Docling)
│ ├── tesseract_engine.py # Baseline OCR engine (Tesseract)
│ └── trocr_engine.py # Experimental OCR engine (TrOCR)
└── metrics/
└── accuracy.py # CER / WER / Char Accuracy utilities

data/
└── benchmarks/
└── pubmed_ocr/
├── *.pdf # Sample PDFs
└── *_gt.json # PubMed-OCR ground truth



Each OCR engine is **isolated**, **interchangeable**, and **CLI-selectable**.

---

## `run_ocr.py` — Main CLI Entrypoint

### Purpose
This file is the **single command-line interface** for running OCR.

It is responsible for:
- Parsing user arguments
- Selecting the OCR engine
- Mapping strategy flags (speed vs accuracy)
- Handling progress callbacks
- Emitting outputs
- Optionally running accuracy metrics

### Key Responsibilities
- Engine selection via `--engine`
- Strategy control via `--strategy`
- Output format control via `--output-format`
- Optional benchmarking via `--ground_truth`

### Supported CLI Flags

```bash
--engine        docling | tesseract | trocr
--strategy      fast | accurate
--output-format text | markdown | json
--ground_truth  path/to/gt.json (optional)
--output        path/to/output (optional)

## engines/base.py — Shared Engine Interface

###Purpose

Defines a common contract for all OCR engines.

###Why It Exists

During development, different OCR engines required different parameters.
To avoid CLI fragmentation, a shared interface was introduced.

Interface Contract
class BaseOCREngine:
    def __init__(self, **kwargs):
        pass

    def process_pdf(self, pdf_path, output_dir=None, progress_cb=None):
        raise NotImplementedError

###Guarantees

All engines must:

Accept flexible constructor arguments

Support a process_pdf method

Return a standardized output dictionary

## engines/docling_engine.py — Primary OCR Engine (Docling)

###Purpose

Implements the main production OCR pipeline using Docling.

### Why Docling

High-quality OCR

Native table structure extraction

Layout-aware document processing

Fully local execution (no cloud dependency)

Configuration Highlights

OCR enabled

Table structure extraction enabled

Remote services disabled

Safe defaults for competition use

### Key Features

Graceful handling of corrupted PDFs

Page count detection

Progress reporting via callback

Text and Markdown export support

Output Format
{
  "text": "...",
  "markdown": "...",
  "pages": 1,
  "time_sec": 12.8
}

## engines/tesseract_engine.py — Baseline OCR Engine (Tesseract)
### Purpose

Provides a fast, classical OCR baseline for comparison.

### Why Tesseract

Lightweight

Widely used

Strong baseline for printed text

CPU-only, fast execution

### System Dependency (Important)

This engine relies on the **native Tesseract OCR binary**, which must be installed separately.

On Windows, the binary path is **explicitly hardcoded** in the engine to avoid PATH-related issues:

```python
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

### Implementation Details

Uses pdf2image + Poppler for PDF rasterization

Uses native Tesseract binary

DPI controlled via --strategy flag

Explicit progress reporting per page

OCR Configuration
--oem 3  (LSTM engine)
--psm 6  (Assume uniform block of text)

### Design Considerations

Explicit constructor accepts dpi

Fully compatible with shared CLI

No layout awareness (expected limitation)

## engines/trocr_engine.py — Experimental OCR Engine (TrOCR)

###Purpose

Included as an experimental deep-learning OCR engine.

###Why TrOCR

Transformer-based OCR

High accuracy on cropped text

Useful for future line-level OCR experiments

Known Limitations

Not designed for full-page scientific PDFs

Slower than Tesseract

No native layout reconstruction

###Role in T1.1

Validates engine isolation

Demonstrates extensibility

Not used as a production engine

## metrics/accuracy.py — OCR Accuracy Utilities
Purpose

Provides standard OCR evaluation metrics.

###Metrics Implemented

Character Error Rate (CER)

Word Error Rate (WER)

Character-level accuracy

###Libraries Used

jiwer for CER / WER

rapidfuzz for Levenshtein distance

Normalization

Light normalization is applied to reduce layout-induced inflation:

Lowercasing

Whitespace normalization

Important Note

Metrics are:

Optional

Only computed when --ground_truth is provided

Not enforced in T1.1


## System Dependencies & Dataset Preparation

This OCR pipeline relies on **native system tools** and **preprocessed benchmark datasets**.  
This section documents how to set them up correctly.

---

## 1. Installing System Dependencies (Windows)

### 1.1 Install Tesseract-OCR (Required for TesseractEngine)

#### Download
- Official installer:  
  https://github.com/UB-Mannheim/tesseract/wiki

Choose the **Windows 64-bit installer**.

#### Installation Path (Important)
Install Tesseract at the default location:


This path is **explicitly referenced** in the code:

```python
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
verify with:
tesseract --version

### 1.2 Install Poppler (Required for PDF Rasterization)

Poppler is required by pdf2image to convert PDF pages into images.

#### Download

Windows binaries:
https://github.com/oschwartz10612/poppler-windows/releases

Download:

Release-XX.X.X-0.zip

####Installation Steps

Extract the ZIP file

Move it to:

C:\Program Files\poppler\


Add Poppler bin directory to PATH:

C:\Program Files\poppler\Library\bin

Verify Installation
pdfinfo -v


If Poppler is correctly installed, version details will appear.


### 1.3 Python Dependencies

Install Python dependencies inside the virtual environment:

pip install pytesseract pdf2image jiwer rapidfuzz transformers torch pillow

## 2. Dataset Preparation (HuggingFace Parquet → PDF + JSON)

Some benchmark datasets (e.g. PubMed-OCR, FinTabNet, DocLayNet) are distributed as Parquet files instead of PDF + JSON pairs. These must be preprocessed.

###2.1 Input Dataset Format (Parquet)

Typical HuggingFace OCR parquet files contain records with fields such as:

pdf_id

page

text

ocr (nested structure)

image or pixel_values (optional)

layout / table annotations (dataset-specific)

Example (conceptual):

{
  "id": "PMC4446431",
  "page": 14,
  "ocr": {
    "text": {
      "lines": [
        {"text": "..."},
        {"text": "..."}
      ]
    }
  }
}

###2.2 Preprocessing Objective

The preprocessing step converts:

.parquet  →  PDF + Ground Truth JSON


So that OCR engines can be evaluated under identical conditions.

###2.3 Preprocessing Script

#### Script Overview

Script responsibilities:
- Load a Parquet file using `pandas`
- Validate required columns
- Extract embedded PDF bytes
- Extract OCR ground truth JSON
- Write PDF + JSON pairs to disk

---

#### Script: `preprocess_parquet_to_pdf_json.py`

##### Configuration Section

```python
PARQUET_FILE = r"C:\Users\dewan\AI-FRC\train-00000.parquet"
OUTPUT_DIR = Path(r"C:\Users\dewan\AI-FRC\data\benchmarks")
NUM_SAMPLES = 3

PARQUET_FILE
Path to the HuggingFace-style Parquet file.

OUTPUT_DIR
Target directory where generated PDFs and ground truth JSON files will be written.

NUM_SAMPLES
Number of records to extract (useful for quick validation and debugging).

#####Required Parquet Schema

The script expects the Parquet file to contain the following columns:

Column Name	Description
pdf_bytes	Raw PDF bytes for a single page
ocr_json	OCR ground truth annotation (JSON string)
basename	Document identifier
page	Page number within the document

#####Run the script directly:

python preprocess_parquet_to_pdf_json.py

####2.4 Output Dataset Structure (Required)

After preprocessing, the benchmark directory must follow this structure:

data/
└── benchmarks/
    └── pubmed_ocr/
        ├── gkv371.PMC4446431_p1.pdf
        ├── gkv371.PMC4446431_p1_gt.json
        ├── gkv371.PMC4446431_p2.pdf
        ├── gkv371.PMC4446431_p2_gt.json
        ├── ...


Each PDF page must have a matching ground-truth JSON file.

####2.5 Ground Truth JSON Format (Expected)

Ground truth files must follow the PubMed-OCR schema:

{
  "ocr": {
    "text": {
      "lines": [
        {"text": "First line of text"},
        {"text": "Second line of text"}
      ]
    }
  }
}


This format is required by:

extract_gt_text_from_pubmed_ocr()

##3. Validation Checklist

Before running OCR benchmarks, verify:

 tesseract --version works

 pdfinfo -v works

 Parquet files converted to PDF + JSON

 Each PDF has a matching _gt.json

 Dataset follows the documented directory structure
